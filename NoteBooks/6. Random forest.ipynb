{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "213c1aef",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d65f0d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>...</th>\n",
       "      <th>2007.0</th>\n",
       "      <th>2008.0</th>\n",
       "      <th>2009.0</th>\n",
       "      <th>2010.0</th>\n",
       "      <th>2011.0</th>\n",
       "      <th>2012.0</th>\n",
       "      <th>2013.0</th>\n",
       "      <th>2014.0</th>\n",
       "      <th>2015.0</th>\n",
       "      <th>2016.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "      <td>4635.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2007.369579</td>\n",
       "      <td>0.260723</td>\n",
       "      <td>0.139294</td>\n",
       "      <td>0.037282</td>\n",
       "      <td>0.048949</td>\n",
       "      <td>0.486453</td>\n",
       "      <td>70.496872</td>\n",
       "      <td>28.914995</td>\n",
       "      <td>7.216677</td>\n",
       "      <td>129.731607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.089105</td>\n",
       "      <td>0.082848</td>\n",
       "      <td>0.073355</td>\n",
       "      <td>0.063646</td>\n",
       "      <td>0.064941</td>\n",
       "      <td>0.048975</td>\n",
       "      <td>0.035599</td>\n",
       "      <td>0.034736</td>\n",
       "      <td>0.027184</td>\n",
       "      <td>0.028263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.069156</td>\n",
       "      <td>0.276439</td>\n",
       "      <td>0.183665</td>\n",
       "      <td>0.117220</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.465979</td>\n",
       "      <td>12.903368</td>\n",
       "      <td>18.224541</td>\n",
       "      <td>1.381018</td>\n",
       "      <td>426.797953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284925</td>\n",
       "      <td>0.275682</td>\n",
       "      <td>0.260746</td>\n",
       "      <td>0.244148</td>\n",
       "      <td>0.246448</td>\n",
       "      <td>0.215839</td>\n",
       "      <td>0.185307</td>\n",
       "      <td>0.183129</td>\n",
       "      <td>0.162638</td>\n",
       "      <td>0.165742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1985.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2004.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2007.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2010.000000</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.820000</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>1.490000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>2.070000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>10665.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 975 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Year_of_Release     NA_Sales     EU_Sales     JP_Sales  Other_Sales  \\\n",
       "count      4635.000000  4635.000000  4635.000000  4635.000000  4635.000000   \n",
       "mean       2007.369579     0.260723     0.139294     0.037282     0.048949   \n",
       "std           4.069156     0.276439     0.183665     0.117220     0.068543   \n",
       "min        1985.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        2004.000000     0.070000     0.020000     0.000000     0.010000   \n",
       "50%        2007.000000     0.160000     0.060000     0.000000     0.020000   \n",
       "75%        2010.000000     0.360000     0.190000     0.010000     0.060000   \n",
       "max        2016.000000     1.820000     1.580000     1.490000     1.180000   \n",
       "\n",
       "       Global_Sales  Critic_Score  Critic_Count   User_Score    User_Count  \\\n",
       "count   4635.000000   4635.000000   4635.000000  4635.000000   4635.000000   \n",
       "mean       0.486453     70.496872     28.914995     7.216677    129.731607   \n",
       "std        0.465979     12.903368     18.224541     1.381018    426.797953   \n",
       "min        0.010000     21.000000      3.000000     0.500000      4.000000   \n",
       "25%        0.140000     63.000000     15.000000     6.500000     11.000000   \n",
       "50%        0.320000     72.000000     25.000000     7.500000     25.000000   \n",
       "75%        0.690000     80.000000     40.000000     8.200000     77.000000   \n",
       "max        2.070000     98.000000    106.000000     9.600000  10665.000000   \n",
       "\n",
       "       ...       2007.0       2008.0       2009.0       2010.0       2011.0  \\\n",
       "count  ...  4635.000000  4635.000000  4635.000000  4635.000000  4635.000000   \n",
       "mean   ...     0.089105     0.082848     0.073355     0.063646     0.064941   \n",
       "std    ...     0.284925     0.275682     0.260746     0.244148     0.246448   \n",
       "min    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%    ...     0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max    ...     1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "            2012.0       2013.0       2014.0       2015.0       2016.0  \n",
       "count  4635.000000  4635.000000  4635.000000  4635.000000  4635.000000  \n",
       "mean      0.048975     0.035599     0.034736     0.027184     0.028263  \n",
       "std       0.215839     0.185307     0.183129     0.162638     0.165742  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 975 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Basic Libraries\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mainData = pd.read_csv('clean_filter_dataframe.csv')\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "mainData.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9118146",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_of_Release</th>\n",
       "      <th>NA_Sales</th>\n",
       "      <th>EU_Sales</th>\n",
       "      <th>JP_Sales</th>\n",
       "      <th>Other_Sales</th>\n",
       "      <th>Global_Sales</th>\n",
       "      <th>Critic_Score</th>\n",
       "      <th>Critic_Count</th>\n",
       "      <th>User_Score</th>\n",
       "      <th>User_Count</th>\n",
       "      <th>...</th>\n",
       "      <th>2007.0</th>\n",
       "      <th>2008.0</th>\n",
       "      <th>2009.0</th>\n",
       "      <th>2010.0</th>\n",
       "      <th>2011.0</th>\n",
       "      <th>2012.0</th>\n",
       "      <th>2013.0</th>\n",
       "      <th>2014.0</th>\n",
       "      <th>2015.0</th>\n",
       "      <th>2016.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2005.0</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>2.07</td>\n",
       "      <td>72.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006.0</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>2.07</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>24.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007.0</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.07</td>\n",
       "      <td>73.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.31</td>\n",
       "      <td>2.07</td>\n",
       "      <td>71.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1571.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>1.48</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.06</td>\n",
       "      <td>83.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 975 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_of_Release  NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \\\n",
       "0           2005.0      1.77      0.12      0.02         0.17          2.07   \n",
       "1           2006.0      0.92      0.93      0.00         0.22          2.07   \n",
       "2           2007.0      1.35      0.52      0.00         0.19          2.07   \n",
       "3           2014.0      0.36      1.38      0.02         0.31          2.07   \n",
       "4           2009.0      1.48      0.39      0.00         0.19          2.06   \n",
       "\n",
       "   Critic_Score  Critic_Count  User_Score  User_Count  ...  2007.0  2008.0  \\\n",
       "0          72.0          21.0         7.8        54.0  ...       0       0   \n",
       "1          49.0           5.0         5.2        24.0  ...       0       0   \n",
       "2          73.0          16.0         7.1        27.0  ...       1       0   \n",
       "3          71.0          85.0         6.1      1571.0  ...       0       0   \n",
       "4          83.0          68.0         7.9        51.0  ...       0       0   \n",
       "\n",
       "   2009.0  2010.0  2011.0  2012.0  2013.0  2014.0  2015.0  2016.0  \n",
       "0       0       0       0       0       0       0       0       0  \n",
       "1       0       0       0       0       0       0       0       0  \n",
       "2       0       0       0       0       0       0       0       0  \n",
       "3       0       0       0       0       0       1       0       0  \n",
       "4       1       0       0       0       0       0       0       0  \n",
       "\n",
       "[5 rows x 975 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mainData.drop([\"Name\", 'Developer', 'Publisher', 'Rating', 'Platform', 'Genre'],axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4252a2b0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c96cff",
   "metadata": {},
   "source": [
    "Random Forest Regression is a supervised learning algorithm that consists of a lot of decision trees that help to output the mean of prediction of the individual trees. The reason that the random forest model works so well is because a large number of relatively uncorrelated trees operating as a committee will outperform any of the individual constituent models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5c9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mainData_dummies = data\n",
    "mainData_dummies.iloc[:,5:].head(5)\n",
    "import numpy as np# Labels are the values we want to predict\n",
    "labels = np.array(mainData_dummies['Global_Sales'])# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "mainData_dummies=  mainData_dummies.drop('Global_Sales', axis = 1)# Saving feature names for later use\n",
    "mainData_dummies = mainData_dummies.drop(\"NA_Sales\", axis = 1)\n",
    "mainData_dummies = mainData_dummies.drop(\"EU_Sales\", axis = 1)\n",
    "mainData_dummies = mainData_dummies.drop(\"JP_Sales\", axis = 1)\n",
    "mainData_dummies = mainData_dummies.drop(\"Other_Sales\", axis = 1)\n",
    "\n",
    "mainData_list = list(mainData_dummies.columns)# Convert to numpy array\n",
    "mainData_dummies = np.array(mainData_dummies)\n",
    "from sklearn.model_selection import train_test_split# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(mainData_dummies, labels, test_size = 0.20, random_state = 42)\n",
    "\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)# Train the model on training data\n",
    "rf.fit(X_train, y_train); \n",
    "\n",
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "# Check the Goodness of Fit (on Train Data)\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", rf.score(X_train, y_train))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "print()\n",
    "\n",
    "# Check the Goodness of Fit (on Test Data)\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Explained Variance (R^2) \\t:\", rf.score(X_test, y_test))\n",
    "print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "print()\n",
    "\n",
    "# Plot the Predictions vs the True values\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axes[0].scatter(y_train, y_train_pred, color = \"blue\")\n",
    "axes[0].plot(y_train, y_train, 'r-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test, y_test_pred, color = \"green\")\n",
    "axes[1].plot(y_test, y_test, 'r-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133171b7",
   "metadata": {},
   "source": [
    "As shown here, the train dataset had produced a very good model as the R^2 value almost close to 1. However, the test dataset did not do as well with a R^2 of 0.41 only. There is a huge difference in the R^2 values between the train and test set. We learned that is because the model was overfitted to the train data set. \n",
    "\n",
    "Overfitting means that the regression model has become tailored to fit every single point in the dataset rather than reflecting the overall population. This was why the R^2 of the train dataset was high but when the model was used on the test data set, the R^2 of the test data set was very low. Hence, we decided to use regularisation to calibrate the machine learning model in order to minimise the adjusted loss function and prevent overfitting. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
